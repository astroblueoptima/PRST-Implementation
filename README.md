# Progressive Resource Scarcity Training (PRST) ğŸ§ 

Enhance your machine learning models' training with the innovative PRST approach. Simulate resource constraints during training to achieve robust and efficient learning.

## ğŸŒŸ Highlights

- **Dynamic Adaptation**: Smartly adjusts constraints based on real-time model performance.
- **Embrace Scarcity**: Utilizes a unique data sampling approach, providing varied portions of the dataset during training phases.
- **Built-in Regularization**: Uses dropout techniques out-of-the-box to ensure model generalization.
- **Early Stopping Mechanism**: Keeps an eye on model performance, halting training if things go south, and ensuring optimal model states.

## ğŸš€ Getting Started

1. **Clone and Navigate**:
   ```bash
   git clone <your-repo-link>
   cd PRST-Implementation
2. **Install Dependencies**:
   ```bash
   pip install pandas torch
3. **Run the Magic**:
   ```bash
   python prst_implementation.py
   
Note: Make sure the BTC-USD 5.csv dataset is in the directory for seamless execution!
ğŸ“ˆ Dataset

We're using the BTC-USD 5.csv dataset in this iteration. It provides intriguing data points that allow the PRST approach to showcase its capabilities. Always keep it in the repository root for the best experience.

ğŸ›  Future Roadmap

ğŸŒ Extend PRST to a broader range of models, not just neural networks.
ğŸ” Dive deeper into different constraint types, exploring avenues like model size or computation constraints.
ğŸ¤ Contribute!

Got ideas? Feel free to fork, tweak, and send over a pull request. We appreciate all contributions, be it big features, bug fixes, or simple documentation improvements!
